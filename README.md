# Data Poisoning in Deep Learning: A Survey â˜ ï¸

> Data Poisoning in Deep Learning: A Survey
>
>
> æ·±åº¦å­¦ä¹ ä¸­çš„æ•°æ®æ•°æ®æŠ•æ¯’ï¼šç»¼è¿°


<p align="center">
  <img src="assets/fig1.png" alt="Data poisoning" width="400" height="400"/>
</p>
<p align="center"><b>ğŸ“Œ Fig. 1.</b> Types of Adversarial Attacks.</p>


ğŸ’‰This repository is a collection of resources on **data poisoning in deep learning**, serving as a supplement to our survey paper:  
ğŸ“œ "[Data Poisoning in Deep Learning: A Survey](https://arxiv.org/abs/ )" 

If you have any recommendations for missing work or suggestions, please feel free to:  
âœ¦ [Submit a pull request](https://github.com/YOUR_REPO/Data-Poisoning/pulls)  
âœ¦ [Contact us](mailto:YOUR_EMAIL) âœ‰ï¸  
We appreciate your contributions and feedback! 

## Table of Contents ğŸ“‹
â­ï¸ [Taxonomy of Poisoning Attacks](#taxonomy-of-poisoning-attacks)  
ã€€ğŸ”¹ [Attack Objective](#attack-objective)  
ã€€ğŸ”¹ [Attack Goal](#attack-goal)  
ã€€ğŸ”¹ [Attack Knowledge](#attack-knowledge)  
ã€€ğŸ”¹ [Attack Scope](#attack-scope)  
ã€€ğŸ”¹ [Attack Impact](#attack-impact)  
ã€€ğŸ”¹ [Attack Variability](#attack-variability)  
 
â­ï¸ [DATA POISONING ALGORITHMS](#data-poisoning-algorithms)  
ã€€ğŸ”¹ [Heuristic-based Attacks](#heuristic-based-attacks)  
ã€€ğŸ”¹ [Label Flipping Attacks](#label-flipping-attacks)  
ã€€ğŸ”¹ [Feature Space Attacks](#feature-space-attacks)  
ã€€ğŸ”¹ [Bilevel Optimization Attacks](#bilevel-optimization-attacks)  
ã€€ğŸ”¹ [Influence-based Attacks](#influence-based-attacks)  
ã€€ğŸ”¹ [Generative Attacks](#generative-attacks)  
 
â­ï¸ [DATA POISONING IN LARGE LANGUAGE MODELS](#data-poisoning-in-large-language-models)  
ã€€ğŸ”¹ [Pre-training](#pre-training)  
ã€€ğŸ”¹ [Fine-tuning](#fine-tuning)  
ã€€ğŸ”¹ [Preference Alignment](#preference-alignment)  
ã€€ğŸ”¹ [Instruction Tuning](#instruction-tuning)  
ã€€ğŸ”¹ [Prefix Tuning](#prefix-tuning)  
ã€€ğŸ”¹ [In-Context Learning Phase](#in-context-learning-icl-phase)  
ã€€ğŸ”¹ [Prompt Injection](#prompt-injection) 


## TAXONOMY OF POISONING ATTACKS

### ğŸ”· Attack Objective
#### ğŸŒ¿ Label Modification Attack
- **Data collection and quality challenges in deep learning: A data-centric ai perspective.**<br>
*Whang, Steven Euijong and Roh, Yuji and Song, Hwanjun and Lee, Jae-Gil.*<br>
The VLDB Journal 2023. [[Paper](https://link.springer.com/article/10.1007/s00778-022-00775-9)]

- **Data collection and quality challenges in deep learning: A data-centric ai perspective.**<br>
*Whang, Steven Euijong and Roh, Yuji and Song, Hwanjun and Lee, Jae-Gil.*<br>
The VLDB Journal 2023. [[Paper](https://link.springer.com/article/10.1007/s00778-022-00775-9)]

#### ğŸŒ¿ Input Modification Attack
#### ğŸŒ¿ Data Modification Attack


### ğŸ”· Attack Goal
#### ğŸŒ¿ Untargeted Attack
- **Data collection and quality challenges in deep learning: A data-centric ai perspective.**<br>
*Whang, Steven Euijong and Roh, Yuji and Song, Hwanjun and Lee, Jae-Gil.*<br>
The VLDB Journal 2023. [[Paper](https://link.springer.com/article/10.1007/s00778-022-00775-9)]

- **Data collection and quality challenges in deep learning: A data-centric ai perspective.**<br>
*Whang, Steven Euijong and Roh, Yuji and Song, Hwanjun and Lee, Jae-Gil.*<br>
The VLDB Journal 2023. [[Paper](https://link.springer.com/article/10.1007/s00778-022-00775-9)]

#### ğŸŒ¿ Targeted Attack
#### ğŸŒ¿ Backdoor Attack

### ğŸ”· Attack Knowledge

## Citation ğŸ“– 
The manuscript is avaliable in arXiv:
```sh
"Data Poisoning in Deep Learning: A Survey". arXiv preprint arXiv: [pdf]
```
