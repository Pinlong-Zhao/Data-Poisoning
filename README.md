# Data Optimization in Deep Learning: A Survey â˜ ï¸

> Data Poisoning in Deep Learning: A Survey
>
>
> æ·±åº¦å­¦ä¹ ä¸­çš„æ•°æ®æ•°æ®æŠ•æ¯’ï¼šç»¼è¿°

<figure>
  <img src="assets/fig1.png" alt="Data poisoning" width="400" height="400"/>
  <figcaption>Fig. 1. Types of Adversarial Attacks.</figcaption>
</figure>


ğŸ’‰This repository is a collection of resources on **data poisoning in deep learning**, serving as a supplement to our survey paper:  
ğŸ“„ "[Data Poisoning in Deep Learning: A Survey](https://arxiv.org/abs/ )" 

If you have any recommendations for missing work or suggestions, please feel free to:  
ğŸ”¹ [Submit a pull request](https://github.com/YOUR_REPO/Data-Poisoning/pulls)  
ğŸ”¹ [Contact us](mailto:YOUR_EMAIL) âœ‰ï¸  
We appreciate your contributions and feedback! 

## Table of Contents
- [TAXONOMY OF POISONING ATTACKS](#taxonomy-of-poisoning-attacks)
  - [Attack Objective](#attack-objective)


#TAXONOMY OF POISONING ATTACKS

###Attack Objective

## Citation
The manuscript is avaliable in arXiv:
```sh
"Data Poisoning in Deep Learning: A Survey". arXiv preprint arXiv: [pdf]
```
